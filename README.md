![Krogan on Tuchanka](/krogan.png)
# ToDo
Пока нет, но должно появится в следующих итерациях:
- S3 архивирование (в том числе чтобы добирать недостающие страницы при репликации)
- Централизованая аутентификация пользователей PostgreSQL (в том числе логинов для репликации)
- Настройки для Zabbix
- Миграция БД между кластерами
- Апгрейд PostgreSQL (перенос всех БД на новый кластер)
- Общие сервисы для всех БД, например *pg_cron*.

# Введение
Это прототип отказоустойчивого кластера на базе Pacemaker и PostgreSQL для двух датацентров. Кластер разворачивается на виртуалках VirtualBox. Всего будет развернуто 9 виртуалок (суммарно 28GiB), которые образуют 3 отказоустойчивых кластера (разные варианты). Подробности нарисованы в [HAPgSQLStructure](HAPgSQLStructure.key). Первые два кластера состоят из двух серверов PostgreSQL, которые размещены в разных датацентрах и общего witness сервера (размещенный на дешевой виртуалке в третьем датацентре), который разрешает неопределенность 50%/50% отдавая свой голос одной из сторон. Третий кластер состоит из четырех серверов PostgreSQL, по два на датацентр, один мастер, остальные реплики, выдерживает отказ двух серверов или одного датацентра. Это решение может быть, при необходимости, масштабировано на большее число реплик.

Сервис точного времени `ntpd` тоже перенастроен для отказоустойчивости, но там используются методы самого `ntpd` (_orphan mode_). Полная сетевая изоляция, конечно, маловероятна в продакшине, где каждый сервер кластера размещен в независимом датацентре, но возможна на этапе тестирвания, например, на ноутбуках. При полной сетевой изоляции кластера сервер witness начинает выполнять роль центрального ntp сервера раздавая своё время всем кластерам, тем самым синхронизируя все сервера между собой. В случае если и witness выйдет из строя/окажется изолированным, тогда своё время начнет раздавать один из серверов кластера (внутри кластера).

# Список файлов
#### README.md
Этот файл, краткое описание всего.

#### HAPgSQLStructure.key
Картинки для презентации. Открывается в Keynote.app (презентации под MacOs).

#### script/
Bash скрипты для создания и удаления виртуалок.

#### pcs/
Шелловские скрипты, запускаться будут на виртуалках, содержат команды для `pcs`, которые описывают конфигурацию кластера.

#### heartbeat/
Скрипты, которые помогают тестировать отказоустойчивость кластера постоянно записывая и читая из специальной базы данных.

#### common/
Файлы общие для всех виртуалок.

#### witness/ tuchanka\*/
Там лежат файлы различающиеся для каждой виртуалки.

# Установка
Не удалось в VirtualBox настроить так, чтобы в одной подсетке был и доступ в Интернет и доступ хоста к виртуалкам. Поэтому в VirtualBox будет по два сетевых интерфейса в каждой виртуалке. Один сетевой интерфейс для связи машин внутри кластера и связи с хостом, второй для доступа в Интернет (сервера точного времени, DNS, пакеты из репозитория). В реальной системе можно будет сделать через один интерфейс, либо полностью задублировать рабочие подсети.

Для моего удобства процесс развертывания автоматизирован. Поскольку процесс инсталяции с образа DVD и доустановка пакетов по сети занимает довольно длительное время, весь процесс установки осуществляется тремя этапами, их подробно опишу ниже, в конце каждого этапа автоматический создается снэпшот. А в начале этапа автоматический переходит на снэпшот предыдущего этапа.
Для моего удобства процесс развертывания автоматизирован, в том числе скрипты автоматический запускают команды _VBoxManager_ такие как: создание скиншотов файловой системы, запуск и остановка виртуалок. Поскольку процесс инсталяции с образа DVD и доустановка пакетов по сети занимает довольно длительное время, весь процесс установки осуществляется тремя этапами, их подробно опишу ниже, в конце каждого этапа автоматический создается снэпшот. А в начале этапа автоматический переходит на снэпшот предыдущего этапа.

Все команды для шелла даны для `bash`. По умолчанию используется конфиг *default_config.bash* из git, рабочий и достаточный. Но если в конфиг надо внести изменения, то надо скопировать *default_config.bash* в *config.bash* и его уже править.

## Создание виртуальный машин
Все виртуальные машины создаются командой:

	script/create_vms <redhat_installation_image.iso> <root_ssh_public_key.pub>

Загрузочный диск должен быть от редхатоподобного дистрибутива 7й версии. Я использовал `CentOS-7-x86_64-Minimal-1810.iso`. Не должно быть **'** в публичном ключе (он там может быть только в комментариях). Скрипт делает:
- Создает вспомогательные конфигурационные файлы (типа hosts, ssh\_config, etc), которые используются в дальнейших этапах.
- Настраивает общую подсетку в VirtualBox.
- В цикле создает и запускает headless все 9 виртуалок: одно ядро, 768MiB ОЗУ, 4GiB виртуальный диск.
- Устанавливает на них Linux из указанного образа: один раздел винчестера, без swap. Переключение раскладок клавиатуры на __Ctrl-Shift__, пароль у root _"changeme"_ (полезен на случай захода через консоль). Хоть и будет писаться, что создаётся еще пользователь vboxuser, он не создаётся. При инсталяции записывается публичный ключ root'а для ssh (тот что указан вторым аргументом).
- Запускает, записывает публичный ключ ssh куда надо.
- Выключает, делает снэпшот `create_vms`.

Время выполнения 11 минут на MacBook Pro. Обратная операция `destroy_vms`: уничтожает всё, что насоздавал предыдущий скрипт.

## Доустановка пакетов
Скрипт `install_soft`:
- Откатывается на снэпшот `create_vms`.
- Устанавливает русскую локаль (с английским `LC_MESSAGES`, пожелание Редера).
- Устанавливает пакеты, делается различие для witness сервера и всех остальных.
- Выключает виртуалки и делает снэпшот `install_soft`.

Время выполнения 25 минуты на MacBook Pro, время выполнения сильно зависит от количества пакетов требующих обновления. Обратная операция `rollback2create_vms`.

## Настройка pacemaker
Скрипт `configure`:
- Откатывает к снэпшоту `install_soft`.
- Копирует на все виртуалки нужные файлы, с разделением на witness и все остальные.
- Настраивает ntpd, для устойчивой работы при сетевой изоляции, например, на случай стенда на ноутах.
- На всех запускает pcsd: REST демон для `pcs`, редхатовская управлялка Pacemaker.
- На witness запускает кворум девайс.
- Создает в pacemaker три кластера, проводит первичную настройку.
- Создает 4 БД (если точнее, кластера PostgreSQL), в нулевом кластере 2 БД, в остальных по одной.
- PAF модуль (pgsqlms) требует, чтобы до запуска через pacemaker, PostgreSQL был запущен в ручном режиме с установившейся репликацией.
- В Pacemaker создает ресурсы в соответствии к созданным DB, прописывает для них плавающие IP.
- Выключает кластера, виртуалки, создает снэпшот `configure`.

Время выполнения 9 минут на MacBook Pro. Обратная операция `rollback2install_soft`.

## БД heartbeat (опционально)
Для тестирования доступности сервиса при тестировании на отказоустойчивость можно создать БД _heartbeat_ внутри кластеров pacemaker.
Для нормальной работы кластера не нужно.
Скрипт `heartbeat`:
- Откатывает к снэпшоту `configure`.
- Стартует виртуалки, стартует кластера.
- Ждет появления пинга на плавающий IP мастера (как критерий, что кластер встал).
- Создает пользователя _heartbeat_ и БД.
- Выключает кластера, виртуалки, делает снэпшот `heartbeat`.

Время выполнения 5 минуты на MacBook Pro. Обратная операция `rollback2configure`.

Шелловские скрипты для тестирования доступности этих БД лежат в директории hearbeat (запускаются на хосте).

## Всё вместе
Для удобства сделал скрипт `make_all`, который последовательно выполняет все вышеописанные скрипты.

# Конфиги на хосте
Для удобства своей работы, я внес следующие изменения в конфиги на хосте.

#### /etc/hosts

Добавил строчки:

	#Tuchanka
	192.168.89.1   tuchanka0a tuchanka0a.tuchanka
	192.168.89.2   tuchanka0b tuchanka0b.tuchanka
	192.168.89.11  tuchanka1a tuchanka1a.tuchanka
	192.168.89.12  tuchanka1b tuchanka1b.tuchanka
	192.168.89.21  tuchanka2a tuchanka2a.tuchanka
	192.168.89.22  tuchanka2b tuchanka2b.tuchanka
	192.168.89.23  tuchanka2c tuchanka2c.tuchanka
	192.168.89.24  tuchanka2d tuchanka2d.tuchanka
	192.168.89.251 witness witness.tuchanka
	192.168.89.101 krogan0a krogan0a.tuchanka
	192.168.89.102 krogan0b krogan0b.tuchanka
	192.168.89.103 krogan1 krogan1.tuchanka
	192.168.89.104 krogan1s1 krogan1s1.tuchanka
	192.168.89.105 krogan2 krogan2.tuchanka
	192.168.89.106 krogan2s1 krogan2s1.tuchanka
	192.168.89.107 krogan2s2 krogan2s2.tuchanka
	192.168.89.108 krogan2s3 krogan2s3.tuchanka
	192.168.89.254 virtualbox virtualbox.tuchanka

#### ~/.ssh/config

Добавил строчки:

	# Tuchanka
	Host tuchanka0a
		HostName 192.168.89.1
	Host tuchanka0b
		HostName 192.168.89.2
	Host tuchanka1a
		HostName 192.168.89.11
	Host tuchanka1b
		HostName 192.168.89.12
	Host tuchanka2a
		HostName 192.168.89.21
	Host tuchanka2b
		HostName 192.168.89.22
	Host tuchanka2c
		HostName 192.168.89.23
	Host tuchanka2d
		HostName 192.168.89.24
	Host witness
		HostName 192.168.89.251
	Host tuchanka0a tuchanka0b tuchanka1a tuchanka1b tuchanka2a tuchanka2b tuchanka2c tuchanka2d witness
		ForwardAgent yes
		ForwardX11 no
		AddKeysToAgent yes
		AddressFamily inet
		BindAddress 192.168.89.254
		CanonicalizeHostname no
		CheckHostIP yes
		Compression no
		HashKnownHosts no
		StrictHostKeyChecking yes
		User root
		UserKnownHostsFile /Users/!my_user!/prog/domclick/tuchanka/script/ssh_known_hosts

В последнюю строку надо будет записать реальный путь к файлу (файл создается при первом запуске `create_vms`).

# Тестирование
Переключение раскладок клавиатуры на виртуалках (в виртуальных консолях) **Ctrl-Shift**, пароль у root "**changeme**" (полезен на случай захода через консоль). Но удобнее работать через `ssh` с аутентификацией через уже заданный в скрипте `create_vms` публичный ключ.

Поскольку все виртуалки объеденены в группы, согласно кластерам, запускать и останавливать группу в приложении VirtualBox можно через правую кнопку мыши на имени группы(кластера). Процессы VirtualBox иногда зависают от _Close/ACPI Shutdown_ (помогает `killall -9 VBoxHeadless`, на хосте) и иногда зависает приложение UI (помогает _ESC-Option-Command_). Запускать либо целиком группу _Tuchanka_, либо запуская _Witness4Tuchanka_ и нужную подгруппу, например _Tuchanka0_. После этого зайти на любую машину нужного кластера и выполнить команду:

	pcs cluster start --all

Кластер автоматический не поднимается (сервер не добавляется в кластер при загрузке) потому, что, по идее, если машина перезагрузилась или включилась, то сисадмин должен проверить причину, устранить, синхронизировать БД и после этого вручную добавить машину в работающий кластер. Если бы машина добавлялась в кластер автоматический при загрузке, то тогда была бы возможна ситуация когда машина постоянно перезагружается, да еще мешает работе кластера.

Внутри виртуалки, находящейся в кластере, состояние кластера можно мониторить скриптом `mon`, находится в /root/bin. Востанавливать БД, после того как она рассинхронизировалась, можно скриптами типа `restore0a`, лежат в /root/bin. Файлы типа `restore0a` или `restore1` только удаляют текущую директорию БД и копируют БД с текущего мастера. А файлы `restore` (созданы только для тестового стенда) выполняют рутинную работу при тестировании: запускают файл типа `restore1`, добавляют ноду в кластер `pcs cluster start` и удаляют сообщения о старых ошибках из кластера `pcs resource cleanup`. На продакшине использовать такие скрипты считаю нецелесообразным, т.к. если причина отказа работы сервера неизвeстна, то сисадмин должен контролировать каждый шаг.

Отключение всех машин в кластере. Сначала можно (но не нужно при массовом _Power Off_) на одной из машин кластера выполнить:

	pcs cluster stop --all

Потом на заголовке группы и на witness _Close/Power Off_, так как **от _Close/ACPI Shutdown_ (на группе) VirtualBox иногда виснет**.

## Heartbeat
Если была установлена БД _heartbeat_ скриптом `script/hearbeat`, то можно использовать скрипты из папки `heartbeat/` (на хосте). Все скрипты коннектятся к плавающим IP, на которых оказываются услуги и пишут/читают текущее время в таблицу heartbeat (состоющую из одной строчки, одного столбца) с частой 0.1 секунды (в идеале).

Все скрипты начинающиеся на heart пишут в плавающие IP принадлежащие мастеру соответствующей БД. Скрипты которые начинаются на reader читают из плавающих IP принадлежащих рабам соответствующей БД, за исключением tuchanka0. Т.к. по схеме с уплотнением рабы услуги не оказывают , плавающих IP у рабов нет, поэтому `reader0a` и `reader0b` читают из мастерских IP.

Чтобы все это работало, на хосте в /etc/hosts должны быть добавлены плавающие IP, как написано выше. Так же должен быть установлен `psql`, например через `brew install postgresql`.

## Пример теста
Пример теста на обесточивание сервера/датацентра.
- Запуск виртуалки Witness4Tuchanka
- Записк кластера (группы виртуалок) Tuchanka1
- Открываем на хосте 4 терминалки.
- В первой: `ssh tuchanka1b`
	- tuchanka1b: `pcs cluster start --all` _(запуск кластера)_
	- tuchanka1b: `mon` _(мониторинг кластера, когда он поднимется)_
- Должна наблюдаться картина:
	- мастер на одном узле,
	- IP мастера (ресурс krogan1IP) там же,
	- раб на другом,
	- его IP (ресурс krogan1sIP) там же.
- Во второй, на хосте: `. heartbeat/heart1.sh` _(мониторинг записи в мастер)_
- В третьей, на хосте: `. heartbeat/reader1s1.sh` _(мониториг чтения из раба)_
- В четвертой терминалке, на хосте: `VBoxManage controlvm  Tuchanka1a poweroff` _("обесточивание" виртуалки)_
- Наблюдаем как это работает. Сначала потупит по таймаутам, потом, в результате должно получится так, что мастер переезжает на единственно оставшуюся виртуалку и оба плавающих IP (мастера и раба) переезжают на неё же. Во-втором и третьем терминале видим, что работа с БД возобновилась.

Восстанавливаем работу кластера:
- Включаем обесточенную виртуаку, в четвертом терминале: `VBoxManage startvm Tuchanka1a`
- Ждем когда загрузится и поднимется ssh.
- В четвертом терминале: `ssh tuchanka1a`.
	- tuchanka1a: `restore1` _(копирует текущую БД с мастера)_
	- tuchanka1a: `pcs cluster start` _(добавляет ноду в кластер)_
- Наблюдаем как на в прошлом выключенной виртуалке поднимается раб и рабский IP переезжает на него.

Выключение кластера:
- После чего в управлялке через правую мышу `Close/Power Off` на группе Tuchanka1 и Witness4Tuchanka.

Другие тесты будут отличаться способом, каким имитируется неисправность, и спецификой работы каждого кластера. Например, обрыв сети можно имитировать командой:\
`VBoxManage controlvm  Tuchanka1a setlinkstate1 off`\
Только надо потом (перед restore) не забыть "починить" сеть командой:\
`VBoxManage controlvm  Tuchanka1a setlinkstate1 on`

Проверял следующие отказы:
- Потеря питания:  `VBoxManage controlvm  Tuchanka1a poweroff`
- Потеря линка: `VBoxManage controlvm  Tuchanka1a setlinkstate1 off`
- Крэш PostgreSQL (master и slave): `kill -KILL`

И следующие административные команды: `disable`, `enable`, `restart`, `ban`, `move`, `clear` (не забывать делать после `ban` и `move`), `standby`, `unstandby` и т.д. (Подробности в документации к _pacemaker_).

## Известные недостатки
- На текущий момент _watchdog демон_ отрабатывает остановку наблюдаемых демонов, но не их зависание. И, как следствие, некорректно отрабатываются неисправности приводящие к зависанию только corosync и pacemaker, но при этом не подвешивающие sbd. Для проверки corosync уже есть **PR#83** (в github у sbd) принят в ветку master. Обещали, что и для pacemaker будет что-то подобное, надеюсь, что к _RedHat 8_ сделают. Но подобные "неисправности" умозрительные, легко имитируется искусствено с помощью, например `killall -s STOP corosync`, но никогда не встречались естественно.
